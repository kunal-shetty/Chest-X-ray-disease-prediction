{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi9Hpr7mR346riqe4VvPN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunal-shetty/Chest-X-ray-disease-prediction/blob/main/ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ_aI6BuTnXP",
        "outputId": "68021ee8-1c29-4795-d9fd-136a0919cf47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "metadata": {
        "id": "V-rJcogqT62N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"/content/drive/MyDrive/Colab Notebooks/outputs/FINAL_clean_data.csv\"\n",
        "IMAGE_ROOT = \"/content/drive/MyDrive/Colab Notebooks/real data/images_0013/images\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# split labels\n",
        "df[\"finding_labels\"] = df[\"finding_labels\"].apply(lambda x: x.split(\"|\"))\n",
        "\n",
        "# build image paths\n",
        "df[\"image_path\"] = df[\"Image Index\"].astype(str).apply(\n",
        "    lambda x: os.path.join(IMAGE_ROOT, x)\n",
        ")\n",
        "\n",
        "df[\"image_exists\"] = df[\"image_path\"].apply(os.path.exists)\n",
        "df = df[df[\"image_exists\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Images that exist:\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XtQFI_tT9D_",
        "outputId": "58aac68e-9ad3-46c4-803d-25aa4ef8595c",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images that exist: 5830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def is_readable(path):\n",
        "#     try:\n",
        "#         with Image.open(path) as img:\n",
        "#             img.verify()\n",
        "#         return True\n",
        "#     except:\n",
        "#         return False\n",
        "\n",
        "# df[\"image_readable\"] = [is_readable(p) for p in tqdm(df[\"image_path\"])]\n",
        "\n",
        "# print(\"Unreadable images:\", (~df[\"image_readable\"]).sum())\n",
        "\n",
        "# df = df[df[\"image_readable\"]].reset_index(drop=True)\n",
        "# print(\"Final usable images:\", len(df))\n"
      ],
      "metadata": {
        "id": "JbaJBp46bu9M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(df[\"finding_labels\"])\n",
        "\n",
        "NUM_CLASSES = len(mlb.classes_)\n",
        "print(\"Number of disease labels:\", NUM_CLASSES)\n"
      ],
      "metadata": {
        "id": "vHCekYvZbwss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9444cd6c-fa85-4900-bd57-eba3318e28b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of disease labels: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
        "\n",
        "train_idx, test_idx = next(\n",
        "    gss.split(df, Y, groups=df[\"Patient ID\"])\n",
        ")\n",
        "\n",
        "train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "test_df  = df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "Y_train = Y[train_idx]\n",
        "Y_test  = Y[test_idx]\n",
        "\n",
        "print(\"Train:\", len(train_df))\n",
        "print(\"Test:\", len(test_df))\n"
      ],
      "metadata": {
        "id": "LZTvprTygslH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f475a84d-9040-4d87-d85c-a6dfb86bde55"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 4655\n",
            "Test: 1175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "VNOFhQWDbyYI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train_mem = [], []\n",
        "X_test,  Y_test_mem  = [], []\n",
        "\n",
        "print(\"Loading TRAIN images into memory...\")\n",
        "for i in tqdm(range(len(train_df))):\n",
        "    try:\n",
        "        img = Image.open(train_df.loc[i, \"image_path\"]).convert(\"RGB\")\n",
        "        img = transform(img)\n",
        "        X_train.append(img)\n",
        "        Y_train_mem.append(torch.tensor(Y_train[i], dtype=torch.float32))\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"Loading TEST images into memory...\")\n",
        "for i in tqdm(range(len(test_df))):\n",
        "    try:\n",
        "        img = Image.open(test_df.loc[i, \"image_path\"]).convert(\"RGB\")\n",
        "        img = transform(img)\n",
        "        X_test.append(img)\n",
        "        Y_test_mem.append(torch.tensor(Y_test[i], dtype=torch.float32))\n",
        "    except:\n",
        "        continue\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k57ymPpvbz4J",
        "outputId": "a0726e22-7b83-42fc-9ae8-19fcd37cf400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading TRAIN images into memory...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███▏      | 1456/4655 [12:37<26:26,  2.02it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.stack(X_train)\n",
        "Y_train_mem = torch.stack(Y_train_mem)\n",
        "\n",
        "X_test = torch.stack(X_test)\n",
        "Y_test_mem = torch.stack(Y_test_mem)\n",
        "\n",
        "print(\"Final train samples:\", X_train.shape[0])\n",
        "print(\"Final test samples:\", X_test.shape[0])\n"
      ],
      "metadata": {
        "id": "EUuuWZpzb1sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    TensorDataset(X_train, Y_train_mem),\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(X_test, Y_test_mem),\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "WtUzMGvmb3Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "2puINKZwb4lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for imgs, labels in tqdm(train_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dxJmVnHNb51-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
        "        preds.append(outputs)\n",
        "        targets.append(labels.numpy())\n",
        "\n",
        "preds = np.vstack(preds)\n",
        "targets = np.vstack(targets)\n",
        "\n",
        "auc = roc_auc_score(targets, preds, average=\"micro\")\n",
        "print(\"TRAIN MICRO-AUROC:\", auc)"
      ],
      "metadata": {
        "id": "2z1lziU5iKe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"label_names\": mlb.classes_\n",
        "}, \"xray_multilabel_model.pth\")\n"
      ],
      "metadata": {
        "id": "DvEVxB32t60J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\n",
        "    \"xray_multilabel_model.pth\",\n",
        "    map_location=device,\n",
        "    weights_only=False\n",
        ")\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(checkpoint[\"label_names\"]))\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "label_names = checkpoint[\"label_names\"]\n"
      ],
      "metadata": {
        "id": "b5sZOcoeuGIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_xray(image_path, threshold=0.5):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = transform(img).unsqueeze(0).to(device)  # add batch dim\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(img)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "    results = {\n",
        "        label_names[i]: float(probs[i])\n",
        "        for i in range(len(label_names))\n",
        "        if probs[i] >= threshold\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "hzi-mTDiuJC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_predict(indices, threshold=0.5):\n",
        "    imgs = torch.stack([X_train[i] for i in indices]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        probs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
        "\n",
        "    for k, idx in enumerate(indices):\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Image index: {idx}\")\n",
        "\n",
        "        age = train_df.loc[idx, \"patient_age\"] if \"patient_age\" in train_df.columns else \"NA\"\n",
        "        gender = train_df.loc[idx, \"gender\"] if \"gender\" in train_df.columns else \"NA\"\n",
        "        view = train_df.loc[idx, \"view_position\"] if \"view_position\" in train_df.columns else \"NA\"\n",
        "\n",
        "        print(f\"Age: {age}, Gender: {gender}, View: {view}\")\n",
        "        print(\"Detected findings:\")\n",
        "\n",
        "        found = False\n",
        "        for i, p in enumerate(probs[k]):\n",
        "            if p >= threshold:\n",
        "                print(f\"• {label_names[i]} → {p:.3f}\")\n",
        "                found = True\n",
        "\n",
        "        if not found:\n",
        "            print(\"• Normal\")\n"
      ],
      "metadata": {
        "id": "AcAo3bw9uXxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_raw(idx):\n",
        "    img = X_train[idx].unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(img)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "    print(f\"\\nRAW probabilities for image index {idx}:\")\n",
        "    for i, p in enumerate(probs):\n",
        "        print(f\"{label_names[i]:25s} : {p:.4f}\")\n"
      ],
      "metadata": {
        "id": "BUU0kjJMwwXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --------------------------------------------------\n",
        "# STEP 1: Get predictions on training data\n",
        "# --------------------------------------------------\n",
        "\n",
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in DataLoader(\n",
        "        TensorDataset(X_train, Y_train_mem),\n",
        "        batch_size=16,\n",
        "        shuffle=False\n",
        "    ):\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
        "        preds.append(outputs)\n",
        "        targets.append(labels.numpy())\n",
        "\n",
        "preds = np.vstack(preds)\n",
        "targets = np.vstack(targets)\n",
        "\n",
        "print(\"Predictions shape:\", preds.shape)\n",
        "print(\"Targets shape:\", targets.shape)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# STEP 2: Plot ROC curves for ALL diseases\n",
        "# --------------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "valid_disease_count = 0\n",
        "auc_scores = {}\n",
        "\n",
        "for i, disease in enumerate(label_names):\n",
        "\n",
        "    # AUROC undefined if only one class present\n",
        "    if len(np.unique(targets[:, i])) < 2:\n",
        "        auc_scores[disease] = None\n",
        "        continue\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(targets[:, i], preds[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.plot(\n",
        "        fpr,\n",
        "        tpr,\n",
        "        lw=1.5,\n",
        "        label=f\"{disease} (AUC={roc_auc:.2f})\"\n",
        "    )\n",
        "\n",
        "    auc_scores[disease] = roc_auc\n",
        "    valid_disease_count += 1\n",
        "\n",
        "# Diagonal reference line\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(f\"ROC Curves for All Diseases (Valid = {valid_disease_count})\")\n",
        "plt.legend(fontsize=8, loc=\"lower right\", ncol=2)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------------------\n",
        "# STEP 3: Print per-disease AUROC table\n",
        "# --------------------------------------------------\n",
        "\n",
        "print(\"\\nPer-Disease AUROC Summary\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for disease, score in auc_scores.items():\n",
        "    if score is None:\n",
        "        print(f\"{disease:25s} : N/A (single class)\")\n",
        "    else:\n",
        "        print(f\"{disease:25s} : {score:.3f}\")\n"
      ],
      "metadata": {
        "id": "4Nxe-ifFw3AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def gradcam_generate(model, img, target_class, target_layer):\n",
        "    \"\"\"\n",
        "    Hook-free Grad-CAM implementation\n",
        "    \"\"\"\n",
        "    activations = None\n",
        "    gradients = None\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        nonlocal activations\n",
        "        activations = output\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        nonlocal gradients\n",
        "        gradients = grad_out[0]\n",
        "\n",
        "    # Register hooks TEMPORARILY\n",
        "    fh = target_layer.register_forward_hook(forward_hook)\n",
        "    bh = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    # Forward + backward\n",
        "    model.zero_grad()\n",
        "    output = model(img)\n",
        "    score = output[0, target_class]\n",
        "    score.backward()\n",
        "\n",
        "    # Compute Grad-CAM\n",
        "    weights = gradients.mean(dim=(2, 3), keepdim=True)\n",
        "    cam = (weights * activations).sum(dim=1)\n",
        "    cam = F.relu(cam)\n",
        "    cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "    # Remove hooks immediately (IMPORTANT)\n",
        "    fh.remove()\n",
        "    bh.remove()\n",
        "\n",
        "    return cam[0].detach().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "hz5A-IRSxvCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in DataLoader(\n",
        "        TensorDataset(X_train, Y_train_mem),\n",
        "        batch_size=16,\n",
        "        shuffle=False\n",
        "    ):\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
        "        preds.append(outputs)\n",
        "        targets.append(labels.numpy())\n",
        "\n",
        "preds = np.vstack(preds)\n",
        "targets = np.vstack(targets)\n"
      ],
      "metadata": {
        "id": "OS3CyBtr3qcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "infer_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "zfS4l-Pv83yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def safe_load_image(path):\n",
        "    try:\n",
        "        # OpenCV read (much more stable with Drive)\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            raise ValueError(\"cv2.imread failed\")\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Skipping image due to read error: {path}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Ruv3bL669cCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for idx in range(50):\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Image index: {idx}\")\n",
        "\n",
        "    age = train_df.loc[idx, \"patient_age\"] if \"patient_age\" in train_df.columns else \"NA\"\n",
        "    gender = train_df.loc[idx, \"gender\"] if \"gender\" in train_df.columns else \"NA\"\n",
        "    view = train_df.loc[idx, \"view_position\"] if \"view_position\" in train_df.columns else \"NA\"\n",
        "\n",
        "    img = X_train[idx].unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(img)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "    print(\"\\nRaw Output Probabilities (%):\")\n",
        "    for i, p in enumerate(probs):\n",
        "        print(f\"{label_names[i]:25s} : {p*100:.2f}%\")\n",
        "\n",
        "    detected = [(i, p) for i, p in enumerate(probs) if p >= 0.6]\n",
        "\n",
        "    print(\"\\nDetected Findings (threshold = 60%):\")\n",
        "    if not detected:\n",
        "        print(\"• Normal (no abnormal findings)\")\n",
        "        continue\n",
        "\n",
        "    for i, p in detected:\n",
        "        print(f\"• {label_names[i]} → {p*100:.2f}%\")\n",
        "\n",
        "    top_class = max(detected, key=lambda x: x[1])[0]\n",
        "\n",
        "    # ---- Grad-CAM for TOP prediction ----\n",
        "    top_class = max(detected, key=lambda x: x[1])[0]\n",
        "\n",
        "    cam = gradcam_generate(model=model, img=img, target_class=top_class, target_layer=model.layer4)\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "\n",
        "    original = X_train[idx].permute(1, 2, 0).cpu().numpy()\n",
        "    original = (original - original.min()) / (original.max() - original.min() + 1e-8)\n",
        "\n",
        "    overlay = 0.6 * original + 0.4 * heatmap / 255.0\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(overlay)\n",
        "    plt.title(f\"Grad-CAM → {label_names[top_class]}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "XWISLx9JuMXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For user input images\n",
        "\n",
        "# user_images = [\n",
        "#     \"/content/drive/MyDrive/Colab Notebooks/real data/images_0013/images/00003929_000.png\"\n",
        "# ]\n",
        "\n",
        "# for idx, img_path in enumerate(user_images):\n",
        "\n",
        "#     print(\"=\" * 70)\n",
        "#     print(f\"User Image {idx+1}: {img_path}\")\n",
        "\n",
        "#     # ---- Load image ----\n",
        "#     img_pil = safe_load_image(img_path)\n",
        "#     if img_pil is None:\n",
        "#       continue  # skip this image safely\n",
        "\n",
        "#     img_tensor = infer_transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "#     # ---- Inference ----\n",
        "#     with torch.no_grad():\n",
        "#         logits = model(img_tensor)\n",
        "#         probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "#     # ---- Raw probabilities ----\n",
        "#     print(\"\\nRaw Output Probabilities (%):\")\n",
        "#     for i, p in enumerate(probs):\n",
        "#         print(f\"{label_names[i]:25s} : {p*100:.2f}%\")\n",
        "\n",
        "#     # ---- Thresholding ----\n",
        "#     detected = [(i, p) for i, p in enumerate(probs) if p >= 0.3]\n",
        "\n",
        "#     print(\"\\nDetected Findings (threshold = 30%):\")\n",
        "#     if not detected:\n",
        "#         print(\"• Normal (no abnormal findings)\")\n",
        "#         continue\n",
        "\n",
        "#     for i, p in detected:\n",
        "#         print(f\"• {label_names[i]} → {p*100:.2f}%\")\n",
        "\n",
        "#     # ---- Grad-CAM only if abnormal ----\n",
        "#     top_class = max(detected, key=lambda x: x[1])[0]\n",
        "\n",
        "#     cam = gradcam_generate(\n",
        "#         model=model,\n",
        "#         img=img_tensor,\n",
        "#         target_class=top_class,\n",
        "#         target_layer=model.layer4\n",
        "#     )\n",
        "\n",
        "#     # ---- Reddish-brown overlay ----\n",
        "#     cam = cam - cam.min()\n",
        "#     cam = cam / (cam.max() + 1e-8)\n",
        "#     cam = cv2.resize(cam, (224, 224))\n",
        "\n",
        "#     CAM_THRESHOLD = 0.4\n",
        "#     cam_mask = cam > CAM_THRESHOLD\n",
        "\n",
        "#     original = np.array(img_pil.resize((224, 224))) / 255.0\n",
        "\n",
        "#     brown_overlay = np.zeros_like(original)\n",
        "#     brown_overlay[..., 0] = cam * 0.9\n",
        "#     brown_overlay[..., 1] = cam * 0.35\n",
        "#     brown_overlay[..., 2] = cam * 0.15\n",
        "\n",
        "#     overlay = original.copy()\n",
        "#     overlay[cam_mask] = (\n",
        "#         0.65 * original[cam_mask] +\n",
        "#         0.35 * brown_overlay[cam_mask]\n",
        "#     )\n",
        "\n",
        "#     plt.figure(figsize=(4, 4))\n",
        "#     plt.imshow(overlay)\n",
        "#     plt.title(f\"Grad-CAM → {label_names[top_class]}\")\n",
        "#     plt.axis(\"off\")\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "j1t3KRIB9x-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}